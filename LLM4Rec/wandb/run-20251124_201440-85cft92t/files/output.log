[34m[1mwandb[0m: Detected [huggingface_hub.inference] in use.
[34m[1mwandb[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
[34m[1mwandb[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/

Initializing DPO trainer...
Extracting prompt in train dataset: 100%|â–ˆ| 14013/14013 [00:01<00:
Applying chat template to train dataset: 100%|â–ˆ| 14013/14013 [00:0
Tokenizing train dataset: 100%|â–ˆ| 14013/14013 [00:33<00:00, 414.11
Extracting prompt in eval dataset: 100%|â–ˆ| 3504/3504 [00:00<00:00,
Applying chat template to eval dataset: 100%|â–ˆ| 3504/3504 [00:00<0
Tokenizing eval dataset: 100%|â–ˆ| 3504/3504 [00:08<00:00, 411.45 ex
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.

ðŸš€ Trainable parameters: 14,966,784
ðŸ“¦ Total parameters:     1,713,639,424
ðŸ“ˆ Percentage:           0.8734%


============================================================
Starting DPO Training...
============================================================
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151645}.
  0%|                                    | 0/3504 [00:00<?, ?it/s]/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  0%|                          | 5/3504 [00:18<3:29:31,  3.59s/it]Traceback (most recent call last):

{'loss': 0.6921, 'grad_norm': 8.497920036315918, 'learning_rate': 4.995719178082192e-05, 'rewards/chosen': -0.08708267658948898, 'rewards/rejected': -0.09269199520349503, 'rewards/accuracies': 0.4375, 'rewards/margins': 0.005609322339296341, 'logps/chosen': -542.890869140625, 'logps/rejected': -523.8837890625, 'logits/chosen': -1.1452926397323608, 'logits/rejected': -1.1816534996032715, 'epoch': 0.0}
  File "/shared/data3/yanzhen4/LLM4Rec/train_dpo.py", line 247, in <module>
    dpo_trainer.train()
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/transformers/trainer.py", line 2674, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/transformers/trainer.py", line 4020, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py", line 1826, in compute_loss
    loss, metrics = self.get_batch_loss_metrics(model, inputs, train_eval="train")
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py", line 1742, in get_batch_loss_metrics
    model_output = self.concatenated_forward(model, batch)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py", line 1616, in concatenated_forward
    outputs = model(input_ids, **model_kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/accelerate/utils/operations.py", line 819, in forward
    return model_forward(*args, **kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/accelerate/utils/operations.py", line 807, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/peft/peft_model.py", line 1923, in forward
    return self.base_model(
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/peft/tuners/tuners_utils.py", line 308, in forward
    return self.model.forward(*args, **kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 449, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 384, in forward
    hidden_states = decoder_layer(
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/transformers/modeling_layers.py", line 93, in __call__
    return self._gradient_checkpointing_func(partial(super().__call__, **kwargs), *args)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/utils/checkpoint.py", line 496, in checkpoint
    return CheckpointFunction.apply(function, preserve, *args)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/autograd/function.py", line 581, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/utils/checkpoint.py", line 244, in forward
    ctx.fwd_devices, ctx.fwd_device_states = get_device_states(*args)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/utils/checkpoint.py", line 176, in get_device_states
    device_module = _get_device_module(_infer_device_type(*args))
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/utils/checkpoint.py", line 137, in _infer_device_type
    tree_map(add_device_types, args)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/utils/_pytree.py", line 1374, in tree_map
    leaves, treespec = tree_flatten(tree, is_leaf=is_leaf)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/utils/_pytree.py", line 1286, in tree_flatten
    treespec = helper(tree, leaves)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/utils/_pytree.py", line 1283, in helper
    return TreeSpec(node_type, context, subspecs)
  File "<string>", line 6, in __init__
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/utils/_pytree.py", line 1070, in __post_init__
    num_leaves = sum(spec.num_leaves for spec in self.children_specs)
KeyboardInterrupt
Traceback (most recent call last):
  File "/shared/data3/yanzhen4/LLM4Rec/train_dpo.py", line 247, in <module>
    dpo_trainer.train()
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/transformers/trainer.py", line 2674, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/transformers/trainer.py", line 4020, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py", line 1826, in compute_loss
    loss, metrics = self.get_batch_loss_metrics(model, inputs, train_eval="train")
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py", line 1742, in get_batch_loss_metrics
    model_output = self.concatenated_forward(model, batch)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py", line 1616, in concatenated_forward
    outputs = model(input_ids, **model_kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/accelerate/utils/operations.py", line 819, in forward
    return model_forward(*args, **kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/accelerate/utils/operations.py", line 807, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/peft/peft_model.py", line 1923, in forward
    return self.base_model(
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/peft/tuners/tuners_utils.py", line 308, in forward
    return self.model.forward(*args, **kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 449, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 384, in forward
    hidden_states = decoder_layer(
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/transformers/modeling_layers.py", line 93, in __call__
    return self._gradient_checkpointing_func(partial(super().__call__, **kwargs), *args)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/utils/checkpoint.py", line 496, in checkpoint
    return CheckpointFunction.apply(function, preserve, *args)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/autograd/function.py", line 581, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/utils/checkpoint.py", line 244, in forward
    ctx.fwd_devices, ctx.fwd_device_states = get_device_states(*args)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/utils/checkpoint.py", line 176, in get_device_states
    device_module = _get_device_module(_infer_device_type(*args))
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/utils/checkpoint.py", line 137, in _infer_device_type
    tree_map(add_device_types, args)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/utils/_pytree.py", line 1374, in tree_map
    leaves, treespec = tree_flatten(tree, is_leaf=is_leaf)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/utils/_pytree.py", line 1286, in tree_flatten
    treespec = helper(tree, leaves)
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/utils/_pytree.py", line 1283, in helper
    return TreeSpec(node_type, context, subspecs)
  File "<string>", line 6, in __init__
  File "/shared/data3/xx19/envs/LLM4Rec/lib/python3.10/site-packages/torch/utils/_pytree.py", line 1070, in __post_init__
    num_leaves = sum(spec.num_leaves for spec in self.children_specs)
KeyboardInterrupt
