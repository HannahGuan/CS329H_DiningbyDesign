[34m[1mwandb[0m: Detected [huggingface_hub.inference] in use.
[34m[1mwandb[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
[34m[1mwandb[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/

Initializing DPO trainer...
Extracting prompt in train dataset: 100%|â–ˆ| 80/80 [00:00<00:00, 8274.83 exam
Applying chat template to train dataset: 100%|â–ˆ| 80/80 [00:00<00:00, 10176.0
Tokenizing train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:00<00:00, 529.17 examples/s]
Extracting prompt in eval dataset: 100%|â–ˆ| 20/20 [00:00<00:00, 4990.55 examp
Applying chat template to eval dataset: 100%|â–ˆ| 20/20 [00:00<00:00, 5066.20 
Tokenizing eval dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 545.03 examples/s]
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.

ðŸš€ Trainable parameters: 14,966,784
ðŸ“¦ Total parameters:     1,713,639,424
ðŸ“ˆ Percentage:           0.8734%


================================================================================
Starting DPO Training...
================================================================================
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151645}.
  0%|                                                | 0/60 [00:00<?, ?it/s]/shared/data3/xx19/envs/yanzhen_env_2/lib/python3.10/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
                                                                            

{'loss': 0.6578, 'grad_norm': 8.38794994354248, 'learning_rate': 4.9166666666666665e-05, 'rewards/chosen': 0.236724853515625, 'rewards/rejected': 0.16119042038917542, 'rewards/accuracies': 0.5, 'rewards/margins': 0.07553444802761078, 'logps/chosen': -538.6365356445312, 'logps/rejected': -497.3704833984375, 'logits/chosen': -0.6023926734924316, 'logits/rejected': -0.6048543453216553, 'epoch': 0.1}
{'loss': 0.6217, 'grad_norm': 8.167236328125, 'learning_rate': 4.75e-05, 'rewards/chosen': 0.9495846033096313, 'rewards/rejected': 0.7656868100166321, 'rewards/accuracies': 0.75, 'rewards/margins': 0.18389780819416046, 'logps/chosen': -531.0746459960938, 'logps/rejected': -474.93524169921875, 'logits/chosen': -0.5127551555633545, 'logits/rejected': -0.5273640155792236, 'epoch': 0.2}
{'loss': 0.8282, 'grad_norm': 9.844610214233398, 'learning_rate': 4.5833333333333334e-05, 'rewards/chosen': 1.4067840576171875, 'rewards/rejected': 1.6243722438812256, 'rewards/accuracies': 0.375, 'rewards/margins': -0.21758806705474854, 'logps/chosen': -479.832763671875, 'logps/rejected': -540.929931640625, 'logits/chosen': -0.48752880096435547, 'logits/rejected': -0.5423563718795776, 'epoch': 0.3}
{'loss': 0.7296, 'grad_norm': 7.730048179626465, 'learning_rate': 4.4166666666666665e-05, 'rewards/chosen': 1.631638765335083, 'rewards/rejected': 1.6738591194152832, 'rewards/accuracies': 0.625, 'rewards/margins': -0.04222031682729721, 'logps/chosen': -533.5266723632812, 'logps/rejected': -503.53240966796875, 'logits/chosen': -0.44126200675964355, 'logits/rejected': -0.4165324568748474, 'epoch': 0.4}
{'loss': 0.6897, 'grad_norm': 6.250260829925537, 'learning_rate': 4.25e-05, 'rewards/chosen': 2.021775722503662, 'rewards/rejected': 1.923122763633728, 'rewards/accuracies': 0.5, 'rewards/margins': 0.09865304827690125, 'logps/chosen': -536.5360717773438, 'logps/rejected': -518.2412109375, 'logits/chosen': -0.5338679552078247, 'logits/rejected': -0.45803889632225037, 'epoch': 0.5}
                                                                            
{'eval_loss': 0.670010507106781, 'eval_runtime': 5.7681, 'eval_samples_per_second': 3.467, 'eval_steps_per_second': 0.867, 'eval_rewards/chosen': 1.9078845977783203, 'eval_rewards/rejected': 1.7471225261688232, 'eval_rewards/accuracies': 0.550000011920929, 'eval_rewards/margins': 0.16076186299324036, 'eval_logps/chosen': -473.96142578125, 'eval_logps/rejected': -500.7594299316406, 'eval_logits/chosen': -0.43745312094688416, 'eval_logits/rejected': -0.4804958403110504, 'epoch': 0.5}
{'loss': 0.8637, 'grad_norm': 6.768921852111816, 'learning_rate': 4.0833333333333334e-05, 'rewards/chosen': 2.0339176654815674, 'rewards/rejected': 2.2604575157165527, 'rewards/accuracies': 0.375, 'rewards/margins': -0.2265399992465973, 'logps/chosen': -537.0753173828125, 'logps/rejected': -542.2645263671875, 'logits/chosen': -0.4659680724143982, 'logits/rejected': -0.5280566811561584, 'epoch': 0.6}
{'loss': 0.799, 'grad_norm': 7.814493656158447, 'learning_rate': 3.9166666666666665e-05, 'rewards/chosen': 1.6617767810821533, 'rewards/rejected': 1.825102686882019, 'rewards/accuracies': 0.375, 'rewards/margins': -0.16332589089870453, 'logps/chosen': -501.333251953125, 'logps/rejected': -480.23876953125, 'logits/chosen': -0.5463845729827881, 'logits/rejected': -0.5645108222961426, 'epoch': 0.7}
{'loss': 0.7819, 'grad_norm': 10.269007682800293, 'learning_rate': 3.7500000000000003e-05, 'rewards/chosen': 1.6374268531799316, 'rewards/rejected': 1.749455213546753, 'rewards/accuracies': 0.5, 'rewards/margins': -0.11202847957611084, 'logps/chosen': -446.8710632324219, 'logps/rejected': -519.2991333007812, 'logits/chosen': -0.47381526231765747, 'logits/rejected': -0.4762890934944153, 'epoch': 0.8}
{'loss': 0.5632, 'grad_norm': 6.526028156280518, 'learning_rate': 3.5833333333333335e-05, 'rewards/chosen': 1.601840615272522, 'rewards/rejected': 1.2422230243682861, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3596176207065582, 'logps/chosen': -517.8411865234375, 'logps/rejected': -508.8733215332031, 'logits/chosen': -0.4814954400062561, 'logits/rejected': -0.5843331217765808, 'epoch': 0.9}
{'loss': 0.6743, 'grad_norm': 9.40786361694336, 'learning_rate': 3.4166666666666666e-05, 'rewards/chosen': 1.6040477752685547, 'rewards/rejected': 1.4992763996124268, 'rewards/accuracies': 0.5, 'rewards/margins': 0.1047714352607727, 'logps/chosen': -524.4385375976562, 'logps/rejected': -510.61810302734375, 'logits/chosen': -0.5136755704879761, 'logits/rejected': -0.5764452815055847, 'epoch': 1.0}
{'eval_loss': 0.6585222482681274, 'eval_runtime': 5.8134, 'eval_samples_per_second': 3.44, 'eval_steps_per_second': 0.86, 'eval_rewards/chosen': 1.488416314125061, 'eval_rewards/rejected': 1.3288218975067139, 'eval_rewards/accuracies': 0.550000011920929, 'eval_rewards/margins': 0.15959441661834717, 'eval_logps/chosen': -478.1560974121094, 'eval_logps/rejected': -504.94244384765625, 'eval_logits/chosen': -0.48113173246383667, 'eval_logits/rejected': -0.5208557844161987, 'epoch': 1.0}
{'loss': 0.3813, 'grad_norm': 3.467214584350586, 'learning_rate': 3.2500000000000004e-05, 'rewards/chosen': 2.098782777786255, 'rewards/rejected': 0.9620899558067322, 'rewards/accuracies': 0.875, 'rewards/margins': 1.136692762374878, 'logps/chosen': -509.8475036621094, 'logps/rejected': -546.0682373046875, 'logits/chosen': -0.5302896499633789, 'logits/rejected': -0.4538598656654358, 'epoch': 1.1}
{'loss': 0.344, 'grad_norm': 4.016050338745117, 'learning_rate': 3.0833333333333335e-05, 'rewards/chosen': 2.1823935508728027, 'rewards/rejected': 0.985012412071228, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1973812580108643, 'logps/chosen': -506.73748779296875, 'logps/rejected': -498.069580078125, 'logits/chosen': -0.468433678150177, 'logits/rejected': -0.5048021674156189, 'epoch': 1.2}
{'loss': 0.3992, 'grad_norm': 6.135083198547363, 'learning_rate': 2.916666666666667e-05, 'rewards/chosen': 1.8112587928771973, 'rewards/rejected': 1.0642955303192139, 'rewards/accuracies': 1.0, 'rewards/margins': 0.7469631433486938, 'logps/chosen': -514.1932373046875, 'logps/rejected': -545.1322631835938, 'logits/chosen': -0.49714571237564087, 'logits/rejected': -0.5590086579322815, 'epoch': 1.3}
{'loss': 0.3004, 'grad_norm': 3.5971386432647705, 'learning_rate': 2.7500000000000004e-05, 'rewards/chosen': 1.9073119163513184, 'rewards/rejected': 0.7390907406806946, 'rewards/accuracies': 1.0, 'rewards/margins': 1.168221354484558, 'logps/chosen': -498.048583984375, 'logps/rejected': -526.282958984375, 'logits/chosen': -0.4943960905075073, 'logits/rejected': -0.4987671971321106, 'epoch': 1.4}
{'loss': 0.2778, 'grad_norm': 4.2247748374938965, 'learning_rate': 2.5833333333333336e-05, 'rewards/chosen': 1.9493660926818848, 'rewards/rejected': 0.580400824546814, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3689651489257812, 'logps/chosen': -495.0418395996094, 'logps/rejected': -525.0223388671875, 'logits/chosen': -0.5255129933357239, 'logits/rejected': -0.5708430409431458, 'epoch': 1.5}
{'eval_loss': 0.6636817455291748, 'eval_runtime': 5.8344, 'eval_samples_per_second': 3.428, 'eval_steps_per_second': 0.857, 'eval_rewards/chosen': 1.241344690322876, 'eval_rewards/rejected': 1.0984092950820923, 'eval_rewards/accuracies': 0.6499999761581421, 'eval_rewards/margins': 0.14293548464775085, 'eval_logps/chosen': -480.6268615722656, 'eval_logps/rejected': -507.24652099609375, 'eval_logits/chosen': -0.5063086748123169, 'eval_logits/rejected': -0.5449394583702087, 'epoch': 1.5}
{'loss': 0.2188, 'grad_norm': 4.039234638214111, 'learning_rate': 2.4166666666666667e-05, 'rewards/chosen': 2.214582920074463, 'rewards/rejected': 0.4703510105609894, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7442317008972168, 'logps/chosen': -490.0152282714844, 'logps/rejected': -507.60089111328125, 'logits/chosen': -0.6367369890213013, 'logits/rejected': -0.5711592435836792, 'epoch': 1.6}
{'loss': 0.2418, 'grad_norm': 4.108476638793945, 'learning_rate': 2.25e-05, 'rewards/chosen': 1.7459378242492676, 'rewards/rejected': 0.3743934631347656, 'rewards/accuracies': 1.0, 'rewards/margins': 1.371544361114502, 'logps/chosen': -567.061767578125, 'logps/rejected': -509.4870300292969, 'logits/chosen': -0.5150502324104309, 'logits/rejected': -0.5873748064041138, 'epoch': 1.7}
{'loss': 0.2094, 'grad_norm': 2.2417380809783936, 'learning_rate': 2.0833333333333336e-05, 'rewards/chosen': 2.0760719776153564, 'rewards/rejected': 0.31270483136177063, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7633671760559082, 'logps/chosen': -481.19964599609375, 'logps/rejected': -495.5040283203125, 'logits/chosen': -0.6488815546035767, 'logits/rejected': -0.6101517677307129, 'epoch': 1.8}
{'loss': 0.1638, 'grad_norm': 3.0405306816101074, 'learning_rate': 1.9166666666666667e-05, 'rewards/chosen': 1.54445219039917, 'rewards/rejected': -0.42127877473831177, 'rewards/accuracies': 1.0, 'rewards/margins': 1.965731143951416, 'logps/chosen': -500.185791015625, 'logps/rejected': -532.1534423828125, 'logits/chosen': -0.653217077255249, 'logits/rejected': -0.7228274345397949, 'epoch': 1.9}
{'loss': 0.2556, 'grad_norm': 3.4257888793945312, 'learning_rate': 1.75e-05, 'rewards/chosen': 1.3855419158935547, 'rewards/rejected': 0.015387725085020065, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3701541423797607, 'logps/chosen': -543.689208984375, 'logps/rejected': -507.34033203125, 'logits/chosen': -0.5685516595840454, 'logits/rejected': -0.6367109417915344, 'epoch': 2.0}
{'eval_loss': 0.6475254893302917, 'eval_runtime': 5.8407, 'eval_samples_per_second': 3.424, 'eval_steps_per_second': 0.856, 'eval_rewards/chosen': 0.6399785280227661, 'eval_rewards/rejected': 0.4710734486579895, 'eval_rewards/accuracies': 0.6000000238418579, 'eval_rewards/margins': 0.16890504956245422, 'eval_logps/chosen': -486.6404724121094, 'eval_logps/rejected': -513.5198974609375, 'eval_logits/chosen': -0.5597268342971802, 'eval_logits/rejected': -0.5962684750556946, 'epoch': 2.0}
{'loss': 0.1492, 'grad_norm': 2.3309528827667236, 'learning_rate': 1.5833333333333333e-05, 'rewards/chosen': 1.6449456214904785, 'rewards/rejected': -0.2984512448310852, 'rewards/accuracies': 1.0, 'rewards/margins': 1.943396806716919, 'logps/chosen': -570.9092407226562, 'logps/rejected': -499.6580810546875, 'logits/chosen': -0.5797440409660339, 'logits/rejected': -0.6654192209243774, 'epoch': 2.1}
{'loss': 0.1327, 'grad_norm': 2.8420519828796387, 'learning_rate': 1.4166666666666668e-05, 'rewards/chosen': 1.4220157861709595, 'rewards/rejected': -0.6370094418525696, 'rewards/accuracies': 1.0, 'rewards/margins': 2.059025287628174, 'logps/chosen': -551.0244750976562, 'logps/rejected': -543.6614990234375, 'logits/chosen': -0.5995174646377563, 'logits/rejected': -0.6564476490020752, 'epoch': 2.2}
{'loss': 0.1381, 'grad_norm': 2.4560184478759766, 'learning_rate': 1.25e-05, 'rewards/chosen': 1.2478001117706299, 'rewards/rejected': -0.8143376111984253, 'rewards/accuracies': 1.0, 'rewards/margins': 2.0621376037597656, 'logps/chosen': -492.43377685546875, 'logps/rejected': -575.4154052734375, 'logits/chosen': -0.6006348133087158, 'logits/rejected': -0.7070721387863159, 'epoch': 2.3}
{'loss': 0.1258, 'grad_norm': 1.9846192598342896, 'learning_rate': 1.0833333333333334e-05, 'rewards/chosen': 1.4077351093292236, 'rewards/rejected': -0.7834595441818237, 'rewards/accuracies': 1.0, 'rewards/margins': 2.191194534301758, 'logps/chosen': -500.4872131347656, 'logps/rejected': -545.1326904296875, 'logits/chosen': -0.5668169260025024, 'logits/rejected': -0.5291999578475952, 'epoch': 2.4}
{'loss': 0.1807, 'grad_norm': 3.409925699234009, 'learning_rate': 9.166666666666666e-06, 'rewards/chosen': 1.0922431945800781, 'rewards/rejected': -0.6075664758682251, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6998096704483032, 'logps/chosen': -468.5137939453125, 'logps/rejected': -505.2052917480469, 'logits/chosen': -0.6310703158378601, 'logits/rejected': -0.6086865663528442, 'epoch': 2.5}
{'eval_loss': 0.653657078742981, 'eval_runtime': 5.8478, 'eval_samples_per_second': 3.42, 'eval_steps_per_second': 0.855, 'eval_rewards/chosen': 0.010218661278486252, 'eval_rewards/rejected': -0.13368073105812073, 'eval_rewards/accuracies': 0.6000000238418579, 'eval_rewards/margins': 0.14389938116073608, 'eval_logps/chosen': -492.9380798339844, 'eval_logps/rejected': -519.5675048828125, 'eval_logits/chosen': -0.6132277250289917, 'eval_logits/rejected': -0.6485474705696106, 'epoch': 2.5}
{'loss': 0.1058, 'grad_norm': 2.0909111499786377, 'learning_rate': 7.5e-06, 'rewards/chosen': 1.118849515914917, 'rewards/rejected': -1.2785190343856812, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3973686695098877, 'logps/chosen': -516.16455078125, 'logps/rejected': -496.6702880859375, 'logits/chosen': -0.6613556146621704, 'logits/rejected': -0.7348722815513611, 'epoch': 2.6}
{'loss': 0.0715, 'grad_norm': 1.5898557901382446, 'learning_rate': 5.833333333333334e-06, 'rewards/chosen': 1.443560004234314, 'rewards/rejected': -1.4266204833984375, 'rewards/accuracies': 1.0, 'rewards/margins': 2.870180606842041, 'logps/chosen': -556.966796875, 'logps/rejected': -574.712158203125, 'logits/chosen': -0.6676681637763977, 'logits/rejected': -0.6653178930282593, 'epoch': 2.7}
{'loss': 0.0972, 'grad_norm': 2.3268637657165527, 'learning_rate': 4.166666666666667e-06, 'rewards/chosen': 1.3937249183654785, 'rewards/rejected': -1.3181911706924438, 'rewards/accuracies': 1.0, 'rewards/margins': 2.711915969848633, 'logps/chosen': -522.540283203125, 'logps/rejected': -549.7833251953125, 'logits/chosen': -0.6852142810821533, 'logits/rejected': -0.6060001850128174, 'epoch': 2.8}
{'loss': 0.1201, 'grad_norm': 2.4149327278137207, 'learning_rate': 2.5e-06, 'rewards/chosen': 0.9728649854660034, 'rewards/rejected': -1.382379174232483, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3552441596984863, 'logps/chosen': -463.88916015625, 'logps/rejected': -550.1604614257812, 'logits/chosen': -0.7456858158111572, 'logits/rejected': -0.7821321487426758, 'epoch': 2.9}
{'loss': 0.1465, 'grad_norm': 3.3231348991394043, 'learning_rate': 8.333333333333333e-07, 'rewards/chosen': 0.7686862945556641, 'rewards/rejected': -1.1178443431854248, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8865306377410889, 'logps/chosen': -527.284423828125, 'logps/rejected': -499.7948913574219, 'logits/chosen': -0.6973487138748169, 'logits/rejected': -0.6664702892303467, 'epoch': 3.0}
{'eval_loss': 0.6340384483337402, 'eval_runtime': 5.8595, 'eval_samples_per_second': 3.413, 'eval_steps_per_second': 0.853, 'eval_rewards/chosen': -0.15929612517356873, 'eval_rewards/rejected': -0.3574376106262207, 'eval_rewards/accuracies': 0.6499999761581421, 'eval_rewards/margins': 0.19814148545265198, 'eval_logps/chosen': -494.6332092285156, 'eval_logps/rejected': -521.8050537109375, 'eval_logits/chosen': -0.6329221725463867, 'eval_logits/rejected': -0.6668943166732788, 'epoch': 3.0}
{'train_runtime': 212.995, 'train_samples_per_second': 1.127, 'train_steps_per_second': 0.282, 'train_loss': 0.37562325075268743, 'epoch': 3.0}

================================================================================
Training Complete!
================================================================================

Saving final model to ./outputs/small_test/final_model...
